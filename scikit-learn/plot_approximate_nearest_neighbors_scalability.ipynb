{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "============================================\n",
      "Scalability of Approximate Nearest Neighbors\n",
      "============================================\n",
      "\n",
      "This example studies the scalability profile of approximate 10-neighbors\n",
      "queries using the LSHForest with ``n_estimators=20`` and ``n_candidates=200``\n",
      "when varying the number of samples in the dataset.\n",
      "\n",
      "The first plot demonstrates the relationship between query time and index size\n",
      "of LSHForest. Query time is compared with the brute force method in exact\n",
      "nearest neighbor search for the same index sizes. The brute force queries have a\n",
      "very predictable linear scalability with the index (full scan). LSHForest index\n",
      "have sub-linear scalability profile but can be slower for small datasets.\n",
      "\n",
      "The second plot shows the speedup when using approximate queries vs brute force\n",
      "exact queries. The speedup tends to increase with the dataset size but should\n",
      "reach a plateau typically when doing queries on datasets with millions of\n",
      "samples and a few hundreds of dimensions. Higher dimensional datasets tends to\n",
      "benefit more from LSHForest indexing.\n",
      "\n",
      "The break even point (speedup = 1) depends on the dimensionality and structure\n",
      "of the indexed data and the parameters of the LSHForest index.\n",
      "\n",
      "The precision of approximate queries should decrease slowly with the dataset\n",
      "size. The speed of the decrease depends mostly on the LSHForest parameters and\n",
      "the dimensionality of the data.\n",
      "\n",
      "\"\"\"\n",
      "from __future__ import division\n",
      "print(__doc__)\n",
      "\n",
      "# Authors: Maheshakya Wijewardena <maheshakya.10@cse.mrt.ac.lk>\n",
      "#          Olivier Grisel <olivier.grisel@ensta.org>\n",
      "#\n",
      "# License: BSD 3 clause\n",
      "\n",
      "\n",
      "###############################################################################\n",
      "import time\n",
      "import numpy as np\n",
      "from sklearn.datasets.samples_generator import make_blobs\n",
      "from sklearn.neighbors import LSHForest\n",
      "from sklearn.neighbors import NearestNeighbors\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Parameters of the study\n",
      "n_samples_min = int(1e3)\n",
      "n_samples_max = int(1e5)\n",
      "n_features = 100\n",
      "n_centers = 100\n",
      "n_queries = 100\n",
      "n_steps = 6\n",
      "n_iter = 5\n",
      "\n",
      "# Initialize the range of `n_samples`\n",
      "n_samples_values = np.logspace(np.log10(n_samples_min),\n",
      "                               np.log10(n_samples_max),\n",
      "                               n_steps).astype(np.int)\n",
      "\n",
      "# Generate some structured data\n",
      "rng = np.random.RandomState(42)\n",
      "all_data, _ = make_blobs(n_samples=n_samples_max + n_queries,\n",
      "                         n_features=n_features, centers=n_centers, shuffle=True,\n",
      "                         random_state=0)\n",
      "queries = all_data[:n_queries]\n",
      "index_data = all_data[n_queries:]\n",
      "\n",
      "# Metrics to collect for the plots\n",
      "average_times_exact = []\n",
      "average_times_approx = []\n",
      "std_times_approx = []\n",
      "accuracies = []\n",
      "std_accuracies = []\n",
      "average_speedups = []\n",
      "std_speedups = []\n",
      "\n",
      "# Calculate the average query time\n",
      "for n_samples in n_samples_values:\n",
      "    X = index_data[:n_samples]\n",
      "    # Initialize LSHForest for queries of a single neighbor\n",
      "    lshf = LSHForest(n_estimators=20, n_candidates=200,\n",
      "                     n_neighbors=10).fit(X)\n",
      "    nbrs = NearestNeighbors(algorithm='brute', metric='cosine',\n",
      "                            n_neighbors=10).fit(X)\n",
      "    time_approx = []\n",
      "    time_exact = []\n",
      "    accuracy = []\n",
      "\n",
      "    for i in range(n_iter):\n",
      "        # pick one query at random to study query time variability in LSHForest\n",
      "        query = queries[rng.randint(0, n_queries)]\n",
      "\n",
      "        t0 = time.time()\n",
      "        exact_neighbors = nbrs.kneighbors(query, return_distance=False)\n",
      "        time_exact.append(time.time() - t0)\n",
      "\n",
      "        t0 = time.time()\n",
      "        approx_neighbors = lshf.kneighbors(query, return_distance=False)\n",
      "        time_approx.append(time.time() - t0)\n",
      "\n",
      "        accuracy.append(np.in1d(approx_neighbors, exact_neighbors).mean())\n",
      "\n",
      "    average_time_exact = np.mean(time_exact)\n",
      "    average_time_approx = np.mean(time_approx)\n",
      "    speedup = np.array(time_exact) / np.array(time_approx)\n",
      "    average_speedup = np.mean(speedup)\n",
      "    mean_accuracy = np.mean(accuracy)\n",
      "    std_accuracy = np.std(accuracy)\n",
      "    print(\"Index size: %d, exact: %0.3fs, LSHF: %0.3fs, speedup: %0.1f, \"\n",
      "          \"accuracy: %0.2f +/-%0.2f\" %\n",
      "          (n_samples, average_time_exact, average_time_approx, average_speedup,\n",
      "           mean_accuracy, std_accuracy))\n",
      "\n",
      "    accuracies.append(mean_accuracy)\n",
      "    std_accuracies.append(std_accuracy)\n",
      "    average_times_exact.append(average_time_exact)\n",
      "    average_times_approx.append(average_time_approx)\n",
      "    std_times_approx.append(np.std(time_approx))\n",
      "    average_speedups.append(average_speedup)\n",
      "    std_speedups.append(np.std(speedup))\n",
      "\n",
      "# Plot average query time against n_samples\n",
      "plt.figure()\n",
      "plt.errorbar(n_samples_values, average_times_approx, yerr=std_times_approx,\n",
      "             fmt='o-', c='r', label='LSHForest')\n",
      "plt.plot(n_samples_values, average_times_exact, c='b',\n",
      "         label=\"NearestNeighbors(algorithm='brute', metric='cosine')\")\n",
      "plt.legend(loc='upper left', fontsize='small')\n",
      "plt.ylim(0, None)\n",
      "plt.ylabel(\"Average query time in seconds\")\n",
      "plt.xlabel(\"n_samples\")\n",
      "plt.grid(which='both')\n",
      "plt.title(\"Impact of index size on response time for first \"\n",
      "          \"nearest neighbors queries\")\n",
      "\n",
      "# Plot average query speedup versus index size\n",
      "plt.figure()\n",
      "plt.errorbar(n_samples_values, average_speedups, yerr=std_speedups,\n",
      "             fmt='o-', c='r')\n",
      "plt.ylim(0, None)\n",
      "plt.ylabel(\"Average speedup\")\n",
      "plt.xlabel(\"n_samples\")\n",
      "plt.grid(which='both')\n",
      "plt.title(\"Speedup of the approximate NN queries vs brute force\")\n",
      "\n",
      "# Plot average precision versus index size\n",
      "plt.figure()\n",
      "plt.errorbar(n_samples_values, accuracies, std_accuracies, fmt='o-', c='c')\n",
      "plt.ylim(0, 1.1)\n",
      "plt.ylabel(\"precision@10\")\n",
      "plt.xlabel(\"n_samples\")\n",
      "plt.grid(which='both')\n",
      "plt.title(\"precision of 10-nearest-neighbors queries with index size\")\n",
      "\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}