{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================\n",
      "Restricted Boltzmann Machine features for digit classification\n",
      "==============================================================\n",
      "\n",
      "For greyscale image data where pixel values can be interpreted as degrees of\n",
      "blackness on a white background, like handwritten digit recognition, the\n",
      "Bernoulli Restricted Boltzmann machine model (:class:`BernoulliRBM\n",
      "<sklearn.neural_network.BernoulliRBM>`) can perform effective non-linear\n",
      "feature extraction.\n",
      "\n",
      "In order to learn good latent representations from a small dataset, we\n",
      "artificially generate more labeled data by perturbing the training data with\n",
      "linear shifts of 1 pixel in each direction.\n",
      "\n",
      "This example shows how to build a classification pipeline with a BernoulliRBM\n",
      "feature extractor and a :class:`LogisticRegression\n",
      "<sklearn.linear_model.LogisticRegression>` classifier. The hyperparameters\n",
      "of the entire model (learning rate, hidden layer size, regularization)\n",
      "were optimized by grid search, but the search is not reproduced here because\n",
      "of runtime constraints.\n",
      "\n",
      "Logistic regression on raw pixel values is presented for comparison. The\n",
      "example shows that the features extracted by the BernoulliRBM help improve the\n",
      "classification accuracy.\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named model_selection",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1ae89e05a0d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconvolve\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBernoulliRBM\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named model_selection"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "==============================================================\n",
    "Restricted Boltzmann Machine features for digit classification\n",
    "==============================================================\n",
    "\n",
    "For greyscale image data where pixel values can be interpreted as degrees of\n",
    "blackness on a white background, like handwritten digit recognition, the\n",
    "Bernoulli Restricted Boltzmann machine model (:class:`BernoulliRBM\n",
    "<sklearn.neural_network.BernoulliRBM>`) can perform effective non-linear\n",
    "feature extraction.\n",
    "\n",
    "In order to learn good latent representations from a small dataset, we\n",
    "artificially generate more labeled data by perturbing the training data with\n",
    "linear shifts of 1 pixel in each direction.\n",
    "\n",
    "This example shows how to build a classification pipeline with a BernoulliRBM\n",
    "feature extractor and a :class:`LogisticRegression\n",
    "<sklearn.linear_model.LogisticRegression>` classifier. The hyperparameters\n",
    "of the entire model (learning rate, hidden layer size, regularization)\n",
    "were optimized by grid search, but the search is not reproduced here because\n",
    "of runtime constraints.\n",
    "\n",
    "Logistic regression on raw pixel values is presented for comparison. The\n",
    "example shows that the features extracted by the BernoulliRBM help improve the\n",
    "classification accuracy.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Authors: Yann N. Dauphin, Vlad Niculae, Gabriel Synnaeve\n",
    "# License: BSD\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Setting up\n",
    "\n",
    "def nudge_dataset(X, Y):\n",
    "    \"\"\"\n",
    "    This produces a dataset 5 times bigger than the original one,\n",
    "    by moving the 8x8 images in X around by 1px to left, right, down, up\n",
    "    \"\"\"\n",
    "    direction_vectors = [\n",
    "        [[0, 1, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [1, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 1],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 1, 0]]]\n",
    "\n",
    "    shift = lambda x, w: convolve(x.reshape((8, 8)), mode='constant',\n",
    "                                  weights=w).ravel()\n",
    "    X = np.concatenate([X] +\n",
    "                       [np.apply_along_axis(shift, 1, X, vector)\n",
    "                        for vector in direction_vectors])\n",
    "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
    "    return X, Y\n",
    "\n",
    "# Load Data\n",
    "digits = datasets.load_digits()\n",
    "X = np.asarray(digits.data, 'float32')\n",
    "X, Y = nudge_dataset(X, digits.target)\n",
    "X = (X - np.min(X, 0)) / (np.max(X, 0) + 0.0001)  # 0-1 scaling\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Models we will use\n",
    "logistic = linear_model.LogisticRegression()\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
    "\n",
    "###############################################################################\n",
    "# Training\n",
    "\n",
    "# Hyper-parameters. These were set by cross-validation,\n",
    "# using a GridSearchCV. Here we are not performing cross-validation to\n",
    "# save time.\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 20\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 100\n",
    "logistic.C = 6000.0\n",
    "\n",
    "# Training RBM-Logistic Pipeline\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Training Logistic regression\n",
    "logistic_classifier = linear_model.LogisticRegression(C=100.0)\n",
    "logistic_classifier.fit(X_train, Y_train)\n",
    "\n",
    "###############################################################################\n",
    "# Evaluation\n",
    "\n",
    "print()\n",
    "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        Y_test,\n",
    "        classifier.predict(X_test))))\n",
    "\n",
    "print(\"Logistic regression using raw pixel features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        Y_test,\n",
    "        logistic_classifier.predict(X_test))))\n",
    "\n",
    "###############################################################################\n",
    "# Plotting\n",
    "\n",
    "plt.figure(figsize=(4.2, 4))\n",
    "for i, comp in enumerate(rbm.components_):\n",
    "    plt.subplot(10, 10, i + 1)\n",
    "    plt.imshow(comp.reshape((8, 8)), cmap=plt.cm.gray_r,\n",
    "               interpolation='nearest')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.suptitle('100 components extracted by RBM', fontsize=16)\n",
    "plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "python2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
